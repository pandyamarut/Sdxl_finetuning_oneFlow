{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install \"torch\" \"transformers==4.27.1\" \"diffusers[torch]==0.19.3\"\n",
    "!python3 -m pip uninstall accelerate -y\n",
    "!python3 -m pip install -U onediff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --pre oneflow -f https://oneflow-staging.oss-cn-beijing.aliyuncs.com/branch/master/cu117"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token <Hf_TOKEN>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import oneflow as flow\n",
    "from pathlib import Path\n",
    "from onediff.infer_compiler import oneflow_compile\n",
    "from diffusers import StableDiffusionXLPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def handler(job):\n",
    "#     job_input = job[\"input\"]\n",
    "#     pretrained_model_name_or_path = job_input[\"pretrained_model_name_or_path\"]\n",
    "#     prompt = job_input[\"prompt\"]\n",
    "#     saved_image = job_input[\"saved_output_image\"]\n",
    "#     file_name = job_input[\"compiled_file_name\"]\n",
    "#     job_output = {}\n",
    "\n",
    "#     try:\n",
    "#         if job_input[\"mode\"] == \"compile\":\n",
    "#             # Compilation Mode\n",
    "#             pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "#                 pretrained_model_name_or_path,\n",
    "#                 torch_dtype=torch.float16,\n",
    "#                 variant=\"fp16\",\n",
    "#                 use_safetensors=True,\n",
    "#             )\n",
    "#             pipe.to(\"cuda\")\n",
    "\n",
    "#             pipe.unet = oneflow_compile(pipe.unet)\n",
    "#             if Path(file_name).exists():\n",
    "#                 print(f\"Loading the compiled graph from {file_name}...\")\n",
    "#                 pipe.unet.warmup_with_load(file_name)\n",
    "#             # Save the compiled graph to network storage\n",
    "#             if not Path(file_name).exists():\n",
    "#                 pipe.unet.save_graph(file_name)\n",
    "#                 print(f\"Saved the compiled graph to {file_name}.\")\n",
    "#         elif job_input[\"mode\"] == \"compile_inference\":\n",
    "#             # Compile Inference Mode\n",
    "#             pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "#                 pretrained_model_name_or_path,\n",
    "#                 torch_dtype=torch.float16,\n",
    "#                 variant=\"fp16\",\n",
    "#                 use_safetensors=True,\n",
    "#             )\n",
    "#             pipe.to(\"cuda\")\n",
    "\n",
    "#             # Read the compiled graph from network storage\n",
    "#             if Path(file_name).exists():\n",
    "#                 print(f\"Loading the compiled graph from {file_name}...\")\n",
    "#                 pipe.unet.warmup_with_load(file_name)\n",
    "\n",
    "#             # Perform inference\n",
    "#             image = pipe(prompt).images[0]\n",
    "#             print(f\"Saved the image to {saved_image}.\")\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handler(job):\n",
    "    job_input = job[\"input\"]\n",
    "\n",
    "    pretrained_model_name_or_path = job_input[\"pretrained_model_name_or_path\"]\n",
    "    prompt = job_input[\"prompt\"]\n",
    "    saved_image = job_input[\"saved_output_image\"]\n",
    "    file_name = job_input[\"compiled_file_name\"]\n",
    "    job_output = {}\n",
    "\n",
    "    try:\n",
    "        pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "            pretrained_model_name_or_path,\n",
    "            torch_dtype=torch.float16,\n",
    "            variant=\"fp16\",\n",
    "            use_safetensors=True,\n",
    "        )\n",
    "        pipe.to(\"cuda\")\n",
    "\n",
    "        pipe.unet = oneflow_compile(pipe.unet)\n",
    "        if Path(file_name).exists():\n",
    "            print(f\"Loading the compiled graph from {file_name}...\")\n",
    "            pipe.unet.warmup_with_load(file_name)\n",
    "\n",
    "        image = pipe(prompt).images[0]\n",
    "        print(f\"Saved the image to {saved_image}.\")\n",
    "        image.save(saved_image)\n",
    "\n",
    "        if not Path(file_name).exists():\n",
    "            pipe.unet.save_graph(file_name)\n",
    "            print(f\"Saved the compiled graph to {file_name}.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#runpod.serverless.start({\"handler\": handler}) \n",
    "# Example :  Sample\n",
    "import json\n",
    "\n",
    "# Define the variables\n",
    "pretrained_model_name_or_path = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "prompt = \"photo of two cats fighting\"\n",
    "saved_image = \"sdxl-base-out-.png\"\n",
    "file_name = \"unet_compile\"\n",
    "\n",
    "# Create a dictionary to store the variables\n",
    "data = {\n",
    "    \"pretrained_model_name_or_path\": pretrained_model_name_or_path,\n",
    "    \"prompt\": prompt,\n",
    "    \"saved_output_image\": saved_image,\n",
    "    \"compiled_file_name\": file_name,\n",
    "    \"mode\": \"compile_inference\"\n",
    "}\n",
    "\n",
    "# Convert the dictionary to a JSON object\n",
    "json_object = json.dumps(data, indent=4)\n",
    "\n",
    "\n",
    "handler({\"input\": data})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
